{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lab_image_practice2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOrxpO4lTrnc6U9tYBuQA9Z"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"hJhPAlxR_zNM","colab_type":"code","colab":{}},"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6Hm9O6q0_-sQ","colab_type":"code","colab":{}},"source":["import os\n","import time\n","import math\n","import random\n","import numpy as np\n","import pandas as pd\n","from pathlib import Path\n","import glob\n","import matplotlib.pyplot as plt\n","from PIL import Image, ImageEnhance, ImageOps\n","\n","from tqdm import tqdm, tqdm_notebook\n","\n","import torch\n","from torch import nn, cuda\n","from torch.autograd import Variable \n","import torch.nn.functional as F\n","import torchvision as vision\n","import torchvision.models as models\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam, SGD, Optimizer\n","from torch.optim.lr_scheduler import _LRScheduler, CosineAnnealingLR, ReduceLROnPlateau\n","\n","from sklearn.metrics import f1_scorem"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b4EAjyvSABJl","colab_type":"code","colab":{}},"source":["# seed value fix\n","# seed 값을 고정해야 hyper parameter 바꿀 때마다 결과를 비교할 수 있습니다.\n","def seed_everything(seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","SEED = 2019\n","seed_everything(SEED)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"73MIaKqCACcx","colab_type":"code","colab":{}},"source":["use_cuda = cuda.is_available()\n","use_cuda"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VmY7Y5KeADb9","colab_type":"code","colab":{}},"source":["class TrainDataset(Dataset):\n","    def __init__(self, df, mode='train', transforms=None):\n","        self.df = df\n","        self.mode = mode\n","        self.transform = transforms[self.mode]\n","        \n","    def __len__(self):\n","        return len(self.df)\n","            \n","    def __getitem__(self, idx):\n","        \n","        image = Image.open(TRAIN_IMAGE_PATH / self.df['img_file'][idx]).convert(\"RGB\")\n","\n","        if self.transform:\n","            image = self.transform(image)\n","\n","        label = self.df['class'][idx]\n","\n","        return image, label\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IW_ijnQKAGPZ","colab_type":"code","colab":{}},"source":["class TestDataset(Dataset):\n","    def __init__(self, df, mode='test', transforms=None):\n","        self.df = df\n","        self.mode = mode\n","        self.transform = transforms[self.mode]\n","        \n","    def __len__(self):\n","        return len(self.df)\n","    \n","    def __getitem__(self, idx):\n","        \n","        image = Image.open(TEST_IMAGE_PATH / self.df[idx]).convert(\"RGB\")\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","            \n","        return image  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pU8Ve4wQAHdO","colab_type":"code","colab":{}},"source":["target_size = (224, 224)\n","\n","data_transforms = {\n","    'train': vision.transforms.Compose([\n","        vision.transforms.Resize(target_size),\n","        vision.transforms.RandomHorizontalFlip(),\n","        vision.transforms.RandomRotation(20),\n","        CIFAR10Policy(),\n","        vision.transforms.ToTensor(),\n","        vision.transforms.Normalize(\n","            [0.485, 0.456, 0.406], \n","            [0.229, 0.224, 0.225])\n","    ]),\n","    'valid': vision.transforms.Compose([\n","        vision.transforms.Resize(target_size),\n","        vision.transforms.RandomResizedCrop(target_size, scale=(0.8,1.0)),\n","        vision.transforms.RandomHorizontalFlip(),\n","        vision.transforms.ToTensor(),\n","        vision.transforms.Normalize(\n","            [0.485, 0.456, 0.406], \n","            [0.229, 0.224, 0.225])\n","    ]),\n","        'test': vision.transforms.Compose([\n","        vision.transforms.Resize((224,224)),\n","        vision.transforms.RandomResizedCrop(target_size, scale=(0.8,1.0)),\n","        vision.transforms.ToTensor(),\n","        vision.transforms.Normalize(\n","            [0.485, 0.456, 0.406], \n","            [0.229, 0.224, 0.225])\n","    ]),\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F6KB2sTMAJB1","colab_type":"code","colab":{}},"source":["'''\n","crop된 이미지 사용\n","reference 허태명님 커널: https://www.kaggle.com/tmheo74/3rd-ml-month-car-image-cropping\n","'''\n","\n","TRAIN_IMAGE_PATH = Path('../input/kakl-3rd-cropped-dataset/train_crop/')\n","TEST_IMAGE_PATH = Path('../input/kakl-3rd-cropped-dataset/test_crop/')\n","# train_image_path = Path('../input/2019-3rd-ml-month-with-kakr/train/')\n","# test_image_path = Path('../input/2019-3rd-ml-month-with-kakr/test/')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9BEU8W8vAKS8","colab_type":"code","colab":{}},"source":["# 미리 5 fold로 나누어 csv로 저장한 후 불러왔습니다.\n","# 80프로를 train set으로, 나머지 20프로를 validation set으로 사용합니다. => 수정: 실수로 4 kfold를 해버렸네요 (3/4 train set, 1/4 valid set입니다)\n","df = pd.read_csv(\"../input/car-folds/car_4folds.csv\")\n","test_csv = pd.read_csv('../input/2019-3rd-ml-month-with-kakr/test.csv')\n","df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Vlzf5BOAFJt","colab_type":"code","colab":{}},"source":["# class 분포 고려하여 사전에 split 해놨습니다. fold별 개수 확인 가능\n","len(df[df['fold'] == 0]), len(df[df['fold'] == 1]), len(df[df['fold'] == 2]), len(df[df['fold'] == 3])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QKHa6JIpANU6","colab_type":"code","colab":{}},"source":["train_df = df.loc[df['fold'] != 0]\n","valid_df = df.loc[df['fold'] == 0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u088aBxeAOZI","colab_type":"code","colab":{}},"source":["train_df = train_df[['img_file', 'class']].reset_index(drop=True)\n","valid_df = valid_df[['img_file', 'class']].reset_index(drop=True)\n","x_test = test_csv['img_file']\n","train_df.replace(196, 0, inplace=True) # 대회 데이터 클래스에 0이 없기에 일부러 바꿔줬습니다. model train시 클래스에 0이 없으면 오류 나기 때문에\n","\n","num_classes = train_df['class'].nunique()\n","y_true = valid_df['class'].values # for cv score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wLJfaAzQAPgi","colab_type":"code","colab":{}},"source":["print(\"number of train dataset: {}\".format(len(train_df)))\n","print(\"number of valid dataset: {}\".format(len(valid_df)))\n","print(\"number of classes to predict: {}\".format(num_classes))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Di2L0IOVAQnD","colab_type":"code","colab":{}},"source":["def train_one_epoch(model, criterion, train_loader, optimizer, mixup_loss, accumulation_step=2):\n","    \n","    model.train()\n","    train_loss = 0.\n","    optimizer.zero_grad()\n","\n","    for i, (inputs, targets) in enumerate(train_loader):\n","            \n","        inputs, targets = inputs.cuda(), targets.cuda()\n","\n","        if mixup_loss:\n","            inputs, targets_a, targets_b, lam = mixup_data(inputs, targets, alpha=1.0, use_cuda = use_cuda) # alpha in [0.4, 1.0] 선택 가능\n","            inputs, targets_a, targets_b = map(Variable, (inputs, targets_a, targets_b))\n","            outputs = model(inputs)\n","            loss = mixup_criterion(criterion, outputs.cuda(), targets_a.cuda(), targets_b.cuda(), lam)\n","            \n","        else:\n","            outputs = model(inputs)\n","            loss = criterion(outputs, targets)\n","\n","        loss.backward()\n","         if accumulation_step:\n","            if (i+1) % accumulation_step == 0:  \n","                optimizer.step()\n","                optimizer.zero_grad()\n","        else:\n","            optimizer.step()\n","            optimizer.zero_grad()\n","        \n","\n","        train_loss += loss.item() / len(train_loader)\n","        \n","    return train_loss\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zDIvK9MfAR0h","colab_type":"code","colab":{}},"source":["\n","def validation(model, criterion, valid_loader):\n","    \n","    model.eval()\n","    valid_preds = np.zeros((len(valid_dataset), num_classes))\n","    val_loss = 0.\n","    \n","    with torch.no_grad():\n","        for i, (inputs, targets) in enumerate(valid_loader):\n","\n","            inputs, targets = inputs.cuda(), targets.cuda()\n","            \n","            outputs = model(inputs).detach()\n","            loss = criterion(outputs, targets)\n","            valid_preds[i * batch_size: (i+1) * batch_size] = outputs.cpu().numpy()\n","            \n","            val_loss += loss.item() / len(valid_loader)\n","            \n","        y_pred = np.argmax(valid_preds, axis=1)\n","        val_score = f1_score(y_true, y_pred, average='micro')  \n","        \n","    return val_loss, val_score   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I4YrE3DLAS_z","colab_type":"code","colab":{}},"source":["# 스코어 기준과 loss 기준. lb 점수가 cv score와 비교했을 때 굉장히\n","# consistent해서 cv score를 기준으로 합니다.\n","def pick_best_score(result1, result2):\n","    if result1['best_score'] < result2['best_score']:\n","        return result2\n","    else:\n","        return result1\n","    \n","def pick_best_loss(result1, result2):\n","    if result1['best_loss'] < result2['best_loss']:\n","        return result1\n","    else:\n","        return result2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1LMomAvMAUHU","colab_type":"code","colab":{}},"source":["def train_model(num_epochs=60, accumulation_step=4, mixup_loss=False, cv_checkpoint=False, fine_tune=False, weight_file_name='weight_best.pt', **train_kwargs):\n","    \n","    # choose scheduler\n","    if fine_tune:\n","        lr = 0.00001\n","        optimizer = AdamW(model.parameters(), lr=lr, weight_decay=0.000025)   \n","        scheduler = ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.1)\n","    else:    \n","        lr = 0.01\n","        optimizer = SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=0.025)\n","        eta_min = 1e-6\n","        T_max = 10\n","        T_mult = 1\n","        restart_decay = 0.97\n","        scheduler = CosineAnnealingWithRestartsLR(optimizer,T_max=T_max, eta_min=eta_min, T_mult=T_mult, restart_decay=restart_decay)\n","\n","    train_result = {}\n","    train_result['weight_file_name'] = weight_file_name\n","    best_epoch = -1\n","    best_score = 0.\n","    lrs = []\n","    score = []\n","    \n","    for epoch in range(num_epochs):\n","        \n","        start_time = time.time()\n","\n","        train_loss = train_one_epoch(model, criterion, train_loader, optimizer, mixup_loss, accumulation_step)\n","        val_loss, val_score = validation(model, criterion, valid_loader)\n","        score.append(val_score)\n","    \n","        # model save (score or loss?)\n","        if cv_checkpoint:\n","            if val_score > best_score:\n","                best_score = val_score\n","                train_result['best_epoch'] = epoch + 1\n","                train_result['best_score'] = round(best_score, 5)\n","                torch.save(model.state_dict(), weight_file_name)\n","        else:\n","            if val_loss < best_loss:\n","                best_loss = val_loss\n","                train_result['best_epoch'] = epoch + 1\n","                train_result['best_loss'] = round(best_loss, 5)\n","                torch.save(model.state_dict(), weight_file_name)\n","        \n","        elapsed = time.time() - start_time\n","        lr = [_['lr'] for _ in optimizer.param_groups]\n","        \n","        print(\"Epoch {} - train_loss: {:.4f}  val_loss: {:.4f}  cv_score: {:.4f}  lr: {:.6f}  time: {:.0f}s\".format(\n","                epoch+1, train_loss, val_loss, val_score, lr[0], elapsed))\n","        \n","        for param_group in optimizer.param_groups:\n","            lrs.append(param_group['lr'])\n","        \n","        # scheduler update\n","        if fine_tune:\n","            if cv_checkpoint:\n","                scheduler.step(val_score)\n","            else:\n","                scheduler.step(val_loss)\n","        else:\n","            scheduler.step()\n","     \n","    return train_result, lrs, score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"anJ7NCijAVZv","colab_type":"code","colab":{}},"source":["batch_size = 128\n","\n","train_dataset = TrainDataset(train_df, mode='train', transforms=data_transforms)\n","valid_dataset = TrainDataset(valid_df, mode='valid', transforms=data_transforms)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6nPx9te8AWl-","colab_type":"code","colab":{}},"source":["# baseline이기 때문에 resnet50 사용합니다. 바꿔보세요!\n","model = models.resnet50(pretrained=True)\n","model.fc = nn.Linear(2048, num_classes)\n","model.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"px2FojV7AXl0","colab_type":"code","colab":{}},"source":["criterion = nn.CrossEntropyLoss()\n","\n","train_kwargs = dict(\n","    train_loader=train_loader,\n","    valid_loader=valid_loader,\n","    model=model,\n","    criterion=criterion,\n","    )\n","\n","\n","print(\"training starts\")\n","num_epochs = 120\n","result, lrs, score = train_model(num_epochs=num_epochs, accumulation_step=2, mixup_loss=False, cv_checkpoint=True, fine_tune=False, weight_file_name='weight_best.pt', **train_kwargs)\n","print(result)\n","\n","\n","# finetuning 부분은 전 버전 참고하시면 좋을것 같습니다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8ziAchSAYnR","colab_type":"code","colab":{}},"source":["# 최근에 열린 imet 대회 같은 경우는 학습 시간이 9시간 이상 해야하기 때문에 저장하고 불러오기가 중요합니다\n","# 보통 kaggle에서 딥러닝 대회는 training과 inference는 따로 커널을 만들어서 진행합니다 (저처럼 local gpu 없을 경우 필수)\n","\n","model = models.resnet50() \n","model.fc = nn.Linear(2048, num_classes)\n","model.cuda()\n","model.load_state_dict(torch.load(result['weight_file_name']))\n","\n","batch_size = 1 # 배치 1로 주면 순서대로 나온다\n","test_dataset = TestDataset(x_test, mode='test', transforms=data_transforms)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","model.eval()\n","test_preds = []\n","\n","with torch.no_grad():\n","    for i, images in enumerate(tqdm_notebook(test_loader)):\n","        images = images.cuda()\n","    \n","        preds = model(images).detach()\n","        test_preds.append(preds.cpu().numpy())\n","        "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vaJiW7afAZhv","colab_type":"code","colab":{}},"source":["outputs = []\n","for _ in test_preds:\n","    # argmax를 사용해서 가장 높은 확률로 예측한 class 반환\n","    predicted_class_indices=np.argmax(_, axis=1).tolist()\n","    outputs.append(predicted_class_indices)\n","\n","result = np.concatenate(outputs)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AqJ1qG-6Aaka","colab_type":"code","colab":{}},"source":["submission = pd.read_csv('../input/2019-3rd-ml-month-with-kakr/sample_submission.csv')\n","submission[\"class\"] = result\n","submission[\"class\"].replace(0, 196, inplace=True) # 196에서 0으로 수정했던걸 다시 되돌려준다 \n","submission.to_csv(\"submission.csv\", index=False)\n","submission.head()"],"execution_count":null,"outputs":[]}]}