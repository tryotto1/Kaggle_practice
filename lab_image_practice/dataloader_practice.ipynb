{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"dataloader_practice.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN81w4oVabSUIJfgIIcuqbX"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"IKe77gU_RQ_r","colab_type":"text"},"source":["- Data augmentation을 위한 transformers\n","- epoch마다 처리하는 과정을 간단하게 해주는 dataloader"]},{"cell_type":"code","metadata":{"id":"MG2Lb0ZhQa5v","colab_type":"code","colab":{}},"source":["from __future__ import print_function, division\n","import os\n","import torch\n","import pandas as pd\n","from skimage import io, transform\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, utils\n","\n","# 경고 메시지 무시하기\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","plt.ion()   # 반응형 모드"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zLUEqnX1QkYn","colab_type":"code","colab":{}},"source":["landmarks_frame = pd.read_csv('data/faces/face_landmarks.csv')\n","\n","n = 65\n","img_name = landmarks_frame.iloc[n, 0]\n","landmarks = landmarks_frame.iloc[n, 1:]\n","landmarks = np.asarray(landmarks)\n","landmarks = landmarks.astype('float').reshape(-1, 2)\n","\n","print('Image name: {}'.format(img_name))\n","print('Landmarks shape: {}'.format(landmarks.shape))\n","print('First 4 Landmarks: {}'.format(landmarks[:4]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GpmUeVyCQooh","colab_type":"code","colab":{}},"source":["def show_landmarks(image, landmarks):\n","    \"\"\"Show image with landmarks\"\"\"\n","    \"\"\" 랜드마크(landmark)와 이미지를 보여줍니다. \"\"\"\n","    plt.imshow(image)\n","    plt.scatter(landmarks[:, 0], landmarks[:, 1], s=10, marker='.', c='r')\n","    plt.pause(0.001)  # 갱신이 되도록 잠시 멈춥니다.\n","\n","plt.figure()\n","show_landmarks(io.imread(os.path.join('data/faces/', img_name)),\n","               landmarks)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZwfvmYmhQqtw","colab_type":"code","colab":{}},"source":["class FaceLandmarksDataset(Dataset):\n","    \"\"\"Face Landmarks dataset.\"\"\"\n","\n","    def __init__(self, csv_file, root_dir, transform=None):\n","        \"\"\"\n","        Args:\n","            csv_file (string): csv 파일의 경로\n","            root_dir (string): 모든 이미지가 존재하는 디렉토리 경로\n","            transform (callable, optional): 샘플에 적용될 Optional transform\n","        \"\"\"\n","        self.landmarks_frame = pd.read_csv(csv_file)\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.landmarks_frame)\n","\n","    def __getitem__(self, idx):\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_name = os.path.join(self.root_dir,\n","                                self.landmarks_frame.iloc[idx, 0])\n","        image = io.imread(img_name)\n","        landmarks = self.landmarks_frame.iloc[idx, 1:]\n","        landmarks = np.array([landmarks])\n","        landmarks = landmarks.astype('float').reshape(-1, 2)\n","        sample = {'image': image, 'landmarks': landmarks}\n","\n","        if self.transform:\n","            sample = self.transform(sample)\n","\n","        return sample"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IRSrHW69Qtbt","colab_type":"code","colab":{}},"source":["face_dataset = FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv',\n","                                    root_dir='data/faces/')\n","\n","fig = plt.figure()\n","\n","for i in range(len(face_dataset)):\n","    sample = face_dataset[i]\n","\n","    print(i, sample['image'].shape, sample['landmarks'].shape)\n","\n","    ax = plt.subplot(1, 4, i + 1)\n","    plt.tight_layout()\n","    ax.set_title('Sample #{}'.format(i))\n","    ax.axis('off')\n","    show_landmarks(**sample)\n","\n","    if i == 3:\n","        plt.show()\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZtrZd3sQw7n","colab_type":"code","colab":{}},"source":["    \"\"\"주어진 사이즈로 샘플크기를 조정합니다.\n","\n","    Args:\n","        output_size(tuple or int) : 원하는 사이즈 값\n","            tuple인 경우 해당 tuple(output_size)이 결과물(output)의 크기가 되고,\n","            int라면 비율을 유지하면서, 길이가 작은 쪽이 output_size가 됩니다.\n","    \"\"\"\n","\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, (int, tuple))\n","        self.output_size = output_size\n","\n","    def __call__(self, sample):\n","        image, landmarks = sample['image'], sample['landmarks']\n","\n","        h, w = image.shape[:2]\n","        if isinstance(self.output_size, int):\n","            if h > w:\n","                new_h, new_w = self.output_size * h / w, self.output_size\n","            else:\n","                new_h, new_w = self.output_size, self.output_size * w / h\n","        else:\n","            new_h, new_w = self.output_size\n","\n","        new_h, new_w = int(new_h), int(new_w)\n","\n","        img = transform.resize(image, (new_h, new_w))\n","\n","        landmarks = landmarks * [new_w / w, new_h / h]\n","\n","        return {'image': img, 'landmarks': landmarks}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C53YYSJQQ3l8","colab_type":"code","colab":{}},"source":["class RandomCrop(object):\n","    \"\"\"샘플데이터를 무작위로 자릅니다.\n","\n","    Args:\n","        output_size (tuple or int): 줄이고자 하는 크기입니다.\n","                        int라면, 정사각형으로 나올 것 입니다.\n","    \"\"\"\n","\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, (int, tuple))\n","        if isinstance(output_size, int):\n","            self.output_size = (output_size, output_size)\n","        else:\n","            assert len(output_size) == 2\n","            self.output_size = output_size\n","\n","    def __call__(self, sample):\n","        image, landmarks = sample['image'], sample['landmarks']\n","\n","        h, w = image.shape[:2]\n","        new_h, new_w = self.output_size\n","\n","        top = np.random.randint(0, h - new_h)\n","        left = np.random.randint(0, w - new_w)\n","\n","        image = image[top: top + new_h,\n","                      left: left + new_w]\n","\n","        landmarks = landmarks - [left, top]\n","\n","        return {'image': image, 'landmarks': landmarks}\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GETzR8DiQ61M","colab_type":"code","colab":{}},"source":["class ToTensor(object):\n","    \"\"\"numpy array를 tensor(torch)로 변환 시켜줍니다.\"\"\"\n","\n","    def __call__(self, sample):\n","        image, landmarks = sample['image'], sample['landmarks']\n","\n","        # swap color axis because\n","        # numpy image: H x W x C\n","        # torch image: C X H X W\n","        image = image.transpose((2, 0, 1))\n","        return {'image': torch.from_numpy(image),\n","                'landmarks': torch.from_numpy(landmarks)}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YOE7lUhQQ8c-","colab_type":"code","colab":{}},"source":["scale = Rescale(256)\n","crop = RandomCrop(128)\n","composed = transforms.Compose([Rescale(256),\n","                               RandomCrop(224)])\n","\n","# Apply each of the above transforms on sample.\n","fig = plt.figure()\n","sample = face_dataset[65]\n","for i, tsfrm in enumerate([scale, crop, composed]):\n","    transformed_sample = tsfrm(sample)\n","\n","    ax = plt.subplot(1, 3, i + 1)\n","    plt.tight_layout()\n","    ax.set_title(type(tsfrm).__name__)\n","    show_landmarks(**transformed_sample)\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rnEb-Z7rQ_QG","colab_type":"code","colab":{}},"source":["transformed_dataset = FaceLandmarksDataset(csv_file='data/faces/face_landmarks.csv',\n","                                           root_dir='data/faces/',\n","                                           transform=transforms.Compose([\n","                                               Rescale(256),\n","                                               RandomCrop(224),\n","                                               ToTensor()\n","                                           ]))\n","\n","for i in range(len(transformed_dataset)):\n","    sample = transformed_dataset[i]\n","\n","    print(i, sample['image'].size(), sample['landmarks'].size())\n","\n","    if i == 3:\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DwB69_EhRBEl","colab_type":"code","colab":{}},"source":["dataloader = DataLoader(transformed_dataset, batch_size=4,\n","                        shuffle=True, num_workers=4)\n","\n","\n","# 배치하는 과정을 보여주는 함수입니다.\n","def show_landmarks_batch(sample_batched):\n","    \"\"\"Show image with landmarks for a batch of samples.\"\"\"\n","    images_batch, landmarks_batch = \\\n","            sample_batched['image'], sample_batched['landmarks']\n","    batch_size = len(images_batch)\n","    im_size = images_batch.size(2)\n","    grid_border_size = 2\n","\n","    grid = utils.make_grid(images_batch)\n","    plt.imshow(grid.numpy().transpose((1, 2, 0)))\n","\n","    for i in range(batch_size):\n","        plt.scatter(landmarks_batch[i, :, 0].numpy() + i * im_size + (i + 1) * grid_border_size,\n","                    landmarks_batch[i, :, 1].numpy() + grid_border_size,\n","                    s=10, marker='.', c='r')\n","\n","        plt.title('Batch from dataloader')\n","\n","for i_batch, sample_batched in enumerate(dataloader):\n","    print(i_batch, sample_batched['image'].size(),\n","          sample_batched['landmarks'].size())\n","\n","    # observe 4th batch and stop.\n","    if i_batch == 3:\n","        plt.figure()\n","        show_landmarks_batch(sample_batched)\n","        plt.axis('off')\n","        plt.ioff()\n","        plt.show()\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7kUGSq-LREBN","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}